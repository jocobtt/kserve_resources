{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp \n",
    "from kfp import dsl \n",
    "import kfp.components as comp\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component\n",
    "def download_from_redshift(a, b):\n",
    "    import boto3 \n",
    "    import pandas as pd\n",
    "    import awswrangler as wr\n",
    "    import os\n",
    "    import psycopg2\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "    # with psycopg2 \n",
    "    conn = psycopg2.connect(\n",
    "    host=\"cdo-redshift-cluster-dev.c2nuq0toqpda.us-east-1.redshift.amazonaws.com\",\n",
    "    user=\"collibrain_dataclassification_rs_user\",\n",
    "    port=5439,\n",
    "    password=\"8vC!ZmPuNF4eu#R4G5#V\",\n",
    "    dbname= \"master\")\n",
    "    #cur = conn.cursor() # create a cursor for executing queries\n",
    "\n",
    "    df = pd.read_sql_query('SELECT * FROM collibrain_dataclassification.labels', conn)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # create a simple model since kfp doesn't seem to like being ran just for an etl workload.. \n",
    "    #regressor = DecisionTreeRegressor(random_state=42, max_depth=5)\n",
    "    #regressor.fit(X, y)\n",
    "\n",
    "    \n",
    "    return df.output # kubeflow pipelines is acting weird if I just output this part above alone for some reason\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the above function \n",
    "#download_red = kfp.components.create_component_from_func(download_from_redshift(schema=\"collibrain_dataclassification\", dbname=\"master\", table=\"labels\"), base_image = \"python:3.8\", packages_to_install = [\"boto3\", \"pandas\", \"awswrangler\", \"psycopg2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = \"red etl 2\",\n",
    "    description = \"Pull data from redshift and show it locally.\"\n",
    ")\n",
    "def red_pipeline(a: float, b: float) -> float:\n",
    "    download_red = download_from_redshift()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complr = kfp.compiler.Compiler()\n",
    "complr.compile(red_pipeline, package_path = \"red_etl.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.environ['KF_PIPELINES_SA_TOKEN_PATH'], \"r\") as f:\n",
    "    TOKEN = f.read()\n",
    "\n",
    "client = kfp.Client(\n",
    "    host='http://ml-pipeline.kubeflow.svc.cluster.local:8888',\n",
    "    existing_token=TOKEN)\n",
    "client.create_experiment(\"redshift_etl_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_run_from_pipeline_package(pipeline_file = 'red_etl.yaml', arguments={'a': 2.0}, experiment_name = \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
